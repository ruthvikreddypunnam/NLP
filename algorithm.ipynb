{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793ecebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c042cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b2a416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183531 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \n",
       "0       These flannel wipes are OK, but in my opinion ...       3  \n",
       "1       it came early and was not disappointed. i love...       5  \n",
       "2       Very soft and comfortable and warmer than it l...       5  \n",
       "3       This is a product well worth the purchase.  I ...       5  \n",
       "4       All of my kids have cried non-stop when I trie...       5  \n",
       "...                                                   ...     ...  \n",
       "183526  Such a great idea! very handy to have and look...       5  \n",
       "183527  This product rocks!  It is a great blend of fu...       5  \n",
       "183528  This item looks great and cool for my kids.......       5  \n",
       "183529  I am extremely happy with this product. I have...       5  \n",
       "183530  I love this product very mush . I have bought ...       5  \n",
       "\n",
       "[183531 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b039693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      318\n",
       "review    829\n",
       "rating      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb03a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3911c650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      0\n",
       "review    0\n",
       "rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225fea3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd00f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(x):\n",
    "    if x>=3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7da4b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binnu\\AppData\\Local\\Temp/ipykernel_19772/3971230841.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment']=data['rating'].apply(sentiment)\n"
     ]
    }
   ],
   "source": [
    "data['sentiment']=data['rating'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd56923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182384 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  sentiment  \n",
       "0       These flannel wipes are OK, but in my opinion ...       3          1  \n",
       "1       it came early and was not disappointed. i love...       5          1  \n",
       "2       Very soft and comfortable and warmer than it l...       5          1  \n",
       "3       This is a product well worth the purchase.  I ...       5          1  \n",
       "4       All of my kids have cried non-stop when I trie...       5          1  \n",
       "...                                                   ...     ...        ...  \n",
       "183526  Such a great idea! very handy to have and look...       5          1  \n",
       "183527  This product rocks!  It is a great blend of fu...       5          1  \n",
       "183528  This item looks great and cool for my kids.......       5          1  \n",
       "183529  I am extremely happy with this product. I have...       5          1  \n",
       "183530  I love this product very mush . I have bought ...       5          1  \n",
       "\n",
       "[182384 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafe3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [these, flannel, wipes, are, ok, but, in, my, ...\n",
      "1         [it, came, early, and, was, not, disappointed,...\n",
      "2         [very, soft, and, comfortable, and, warmer, th...\n",
      "3         [this, is, product, well, worth, the, purchase...\n",
      "4         [all, of, my, kids, have, cried, non, stop, wh...\n",
      "                                ...                        \n",
      "183526    [such, great, idea, very, handy, to, have, and...\n",
      "183527    [this, product, rocks, it, is, great, blend, o...\n",
      "183528    [this, item, looks, great, and, cool, for, my,...\n",
      "183529    [am, extremely, happy, with, this, product, ha...\n",
      "183530    [love, this, product, very, mush, have, bought...\n",
      "Name: review, Length: 182384, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "review_vector=data['review'].apply(gensim.utils.simple_preprocess)\n",
    "print(review_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2faf9f7",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06e73097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b7b7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_vector, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ec57ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52201802, 70600435)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_vector, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b521005b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.8250046968460083),\n",
       " ('great', 0.7824597358703613),\n",
       " ('nice', 0.7095295190811157),\n",
       " ('fantastic', 0.6690548062324524),\n",
       " ('excellent', 0.655845582485199),\n",
       " ('reasonable', 0.6456263065338135),\n",
       " ('poor', 0.6294417381286621),\n",
       " ('superb', 0.6275391578674316),\n",
       " ('terrific', 0.5920728445053101),\n",
       " ('neat', 0.5785536170005798)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb79fb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0117874e+00, -2.9596704e-01,  2.7205796e+00,  2.5593543e-01,\n",
       "       -1.1942635e+00,  1.4040507e+00,  2.2292883e+00,  1.0093366e+00,\n",
       "        1.4949924e+00, -1.8712589e+00,  1.3260252e+00,  2.3352902e+00,\n",
       "       -3.0450573e+00,  2.6576692e-02,  3.7250743e+00,  1.5142451e-01,\n",
       "       -1.3041924e+00, -1.4742160e+00, -1.5812613e+00, -2.2929115e+00,\n",
       "        1.0931792e+00, -2.2314360e-02, -3.8274521e-01, -8.3203804e-01,\n",
       "        2.6122208e+00,  4.4107184e+00,  2.9742157e+00, -2.8829989e+00,\n",
       "       -3.8129526e-01,  5.6504947e-01, -5.1987133e+00, -1.3798981e-02,\n",
       "       -1.4889456e-01, -1.5330722e+00,  3.9161048e+00,  2.5207779e-01,\n",
       "        2.1340792e+00, -9.4719660e-01,  2.5963802e+00,  1.5988063e+00,\n",
       "       -2.3259883e+00,  2.3131645e+00,  1.7670436e+00, -1.4934624e+00,\n",
       "        2.1775882e+00,  1.4478289e-01, -2.4234192e+00, -2.2400908e+00,\n",
       "       -1.0209852e+00, -1.0704926e+00, -2.8421912e-01, -1.1016467e+00,\n",
       "       -2.6688716e+00, -2.3085652e-01, -3.3108251e+00, -2.8807466e+00,\n",
       "        2.3895860e+00,  4.1111679e+00,  2.1892343e+00,  8.5364608e-04,\n",
       "       -7.0029855e-01,  1.2053515e+00,  1.2463051e-01, -7.5551969e-01,\n",
       "        3.3058017e-01,  3.4907556e+00,  3.1067634e-01, -9.7494078e-01,\n",
       "       -4.4665937e+00,  5.7434845e-01, -1.8652972e+00,  1.2165151e+00,\n",
       "       -3.0855494e+00, -7.4424303e-01, -1.8534170e+00, -3.9042017e+00,\n",
       "       -1.5739973e+00,  1.7333196e+00, -4.5348468e-01,  8.0311501e-01,\n",
       "        2.8265657e+00,  3.4398227e+00, -2.8292413e+00,  1.2691122e+00,\n",
       "        9.3448406e-01,  3.1473529e+00,  1.3563961e+00, -2.0849858e-01,\n",
       "       -6.8841356e-01, -9.6967107e-01, -2.5026014e+00,  5.4681128e-01,\n",
       "        4.7116879e-01,  1.8405058e+00, -2.1747305e+00, -3.8214350e+00,\n",
       "       -1.4989778e+00, -7.8872871e-01, -2.0268252e+00,  3.2744570e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('good')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5383a",
   "metadata": {},
   "source": [
    "### Feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "994bf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b64c353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom the training data into feature vectors\n",
    "\n",
    "def makeFeatureVec(review, model, num_features):\n",
    "    '''\n",
    "    Transform a review to a feature vector by averaging feature vectors of words \n",
    "    appeared in that review and in the volcabulary list created\n",
    "    '''\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    index2word_set = set(keys) #key is the volcabulary list of the Word2Vec model\n",
    "    isZeroVec = True\n",
    "    review=list(review.split())\n",
    "    for word in review:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model.wv.get_vector(word))\n",
    "            isZeroVec = False\n",
    "    if isZeroVec == False:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    '''\n",
    "    Transform all reviews to feature vectors using makeFeatureVec()\n",
    "    '''\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model,num_features)\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca69f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set : 145907 feature vectors with 100 dimensions\n",
      "Validation set : 36477 feature vectors with 100 dimensions\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'],\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "# Get feature vectors for training set\n",
    "num_features = 100\n",
    "trainVector = getAvgFeatureVecs(X_train, model, num_features)\n",
    "print(\"Training set : %d feature vectors with %d dimensions\" %trainVector.shape)\n",
    "\n",
    "\n",
    "# Get feature vectors for validat\n",
    "testVector = getAvgFeatureVecs(X_test, model, num_features)\n",
    "print(\"Validation set : %d feature vectors with %d dimensions\" %testVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e26bdab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0249407 ,  0.23216245, -0.8775335 , ...,  0.4884561 ,\n",
       "        -0.9277951 , -0.97064257],\n",
       "       [-1.0078005 ,  0.56535304,  0.46996042, ...,  0.58479595,\n",
       "        -0.88835806,  0.4380299 ],\n",
       "       [ 0.1623176 ,  0.08938474,  0.44997248, ...,  0.6730878 ,\n",
       "        -0.5746228 , -0.18311878],\n",
       "       ...,\n",
       "       [ 0.85366553, -0.2965783 ,  0.1562192 , ...,  0.54886264,\n",
       "         0.39000088, -0.29044867],\n",
       "       [ 0.07198919,  0.7802943 ,  0.8511414 , ...,  0.61406165,\n",
       "        -0.4474815 ,  0.38954905],\n",
       "       [ 0.6480639 ,  0.07972667,  0.49908933, ...,  0.07833268,\n",
       "        -0.5837794 ,  0.56441474]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb06c69c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f84a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c45bdae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardize', StandardScaler()),\n",
       "                ('log_reg', LogisticRegression())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "lr = LogisticRegression()\n",
    "model1 = Pipeline([('standardize', scaler),\n",
    "                    ('log_reg', lr)])\n",
    "model1.fit(trainVector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a767f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.04177975162432\n",
      "Confusion matrix:\n",
      " [[ 1857  3439]\n",
      " [  923 30258]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(testVector)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(accuracy)\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a5233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.35      0.46      5296\n",
      "           1       0.90      0.97      0.93     31181\n",
      "\n",
      "    accuracy                           0.88     36477\n",
      "   macro avg       0.78      0.66      0.70     36477\n",
      "weighted avg       0.86      0.88      0.86     36477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd09d7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff3cdd",
   "metadata": {},
   "source": [
    "#### Prediction 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "940b3250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These flannel wipes are OK, but in my opinion not worth keeping.  I also ordered someImse Vimse Cloth Wipes-Ocean Blue-12 countwhich are larger, had a nicer, softer texture and just seemed higher quality.  I use cloth wipes for hands and faces and have been usingThirsties 6 Pack Fab Wipes, Boyfor about 8 months now and need to replace them because they are starting to get rough and have had stink issues for a while that stripping no longer handles.\n"
     ]
    }
   ],
   "source": [
    "review=X_train[0]\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80a2130c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(trainVector[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bf7d5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1822d56c",
   "metadata": {},
   "source": [
    "#### Prediction 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf168603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I purchased this item after reading so many great reviews, but it just didn\\'t work for me with my son. I tried it on a number of different occasions but it was never very effective so I went back to the bulb syringe and had a lot more success. I\\'m glad it works so well for some people, I just wasn\\'t one of them!\n"
     ]
    }
   ],
   "source": [
    "review=X_train[100906]\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24020886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(trainVector[100906].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9418fd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[100906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d779fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2260f428",
   "metadata": {},
   "source": [
    "## The end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23fee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c01fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
